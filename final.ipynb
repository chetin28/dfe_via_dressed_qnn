{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25aef7a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import qiskit\n",
    "from qiskit.quantum_info.operators import Operator, Pauli\n",
    "from qiskit.opflow import CircuitOp, CircuitStateFn\n",
    "from qiskit import *\n",
    "from qiskit.opflow.state_fns import StateFn\n",
    "from qiskit.providers.aer import *\n",
    "from qiskit.opflow.expectations import MatrixExpectation\n",
    "from qiskit.opflow.converters import CircuitSampler\n",
    "from qiskit_experiments.library import StateTomography\n",
    "from qiskit_experiments.framework import ParallelExperiment\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pennylane as qml\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "np.random.seed(31)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c48c590f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def fidel_calculator(data, n_qubits):\n",
    "    fidelities = []\n",
    "    fidelity = 0.0\n",
    "    pj = []\n",
    "    P_j = 0.0\n",
    "    fidel_normal = []\n",
    "    for j in range(n_qubits-1): #loop over batches\n",
    "        for i in range(2**(2*n_qubits)):\n",
    "            fidelity += np.sqrt(data[i][1][j]*data[i][2][j]) / np.sqrt(2**(2*n_qubits))\n",
    "        fidelities.append(fidelity)\n",
    "    for j in range(n_qubits-1):\n",
    "        for i in range(2**(2*n_qubits)):\n",
    "            P_j += data[i][1][j] **2 / 2**n_qubits\n",
    "        pj.append(P_j)\n",
    "    for j in range(n_qubits-1):\n",
    "        a = fidelities[j] / pj[j] #since P_j = sum(a_j **2 / 2**n) = 1, we normalize fidelity using it\n",
    "        fidel_normal.append(a)\n",
    "    return fidel_normal\n",
    "\n",
    "def data_generator(n_qubits):\n",
    "    '''generates data for fidelity trainings\n",
    "    returns data [list] containing elements, datum with structure:\n",
    "    datum = [list of selected pauli operators,\n",
    "            theoretical expectation values, \n",
    "            experimental expectation values,\n",
    "            actual fidelity values ]\n",
    "        '''\n",
    "    data_size = 2**(2*n_qubits)\n",
    "    data = []\n",
    "    fidelity_actual = []\n",
    "    operator_list = []\n",
    "    fidelity = []\n",
    "    expvals_theo = []\n",
    "    expvals_exp = []\n",
    "    diagnosis = []\n",
    "    clbit = []\n",
    "    for j in range(data_size):\n",
    "        #theoretical expectation values\n",
    "        paulis = ['I', 'X', 'Y', 'Z']\n",
    "        W_j = [] # list of selected pauli ops\n",
    "        wj = [] # list of selected paulis for training\n",
    "        op = [] # turn into qiskit ops\n",
    "        randomm = np.random.randint(4,size=n_qubits) # generate random number\n",
    "        for i in range(n_qubits):\n",
    "            ppp = str()\n",
    "            for k in range(n_qubits):\n",
    "                ppp += paulis[randomm[k]]\n",
    "            wj.append(randomm[i])\n",
    "            diagnosis.append(ppp)\n",
    "            W_j.append(ppp) # using that random number, construct W_j\n",
    "                \n",
    "        for i in range(n_qubits):\n",
    "            op.append(Operator(Pauli(W_j[i]))) #turn W_j into Operator list\n",
    "            clbit.append(i)\n",
    "        expvals_th = []\n",
    "        pauli_tensor = []\n",
    "        psi = QuantumCircuit(n_qubits) # arbitrary quantum state for expectation values\n",
    "        psi = CircuitStateFn(psi)\n",
    "        for i in range(n_qubits):\n",
    "            circuit = QuantumCircuit(n_qubits)\n",
    "            #circuit.h(0)\n",
    "            circuit.append(op[i],[(i) for i in range(n_qubits)])\n",
    "            pauli_tensor.append(CircuitOp(circuit))\n",
    "            expval = psi.adjoint().compose(pauli_tensor[i]).compose(psi).eval().real\n",
    "            expvals_th.append(expval)\n",
    "        expvals_theo.append(expvals_th)\n",
    "        \n",
    "        \n",
    "        ## experimental expvals    #### will be changed with ibmq  #######\n",
    "        ''' since actual fidelities are requied, QST will be added to measurement setup '''\n",
    "        \n",
    "        expvals_ex = []\n",
    "        for i in range(n_qubits):\n",
    "            measure = StateFn(pauli_tensor[i], is_measurement=True).compose(psi)\n",
    "            expectation = MatrixExpectation().convert(measure)\n",
    "            sim = AerSimulator()\n",
    "            sampler = CircuitSampler(sim).convert(expectation)\n",
    "            expvals_ex.append(sampler.eval().real)\n",
    "        expvals_exp.append(expvals_ex)\n",
    "                \n",
    "        # actual fidelities\n",
    "        backend = AerSimulator()\n",
    "        #generate list of pauli gates size of n_qubits\n",
    "        tomopaulis = []\n",
    "        for i in range(n_qubits):\n",
    "            zzz = np.random.randint(5,size=1)\n",
    "            if zzz == 0:\n",
    "                tomopaulis.append('I')\n",
    "            elif zzz == 1:\n",
    "                tomopaulis.append('X')\n",
    "            elif zzz == 2:\n",
    "                tomopaulis.append('Y')\n",
    "            else:\n",
    "                tomopaulis.append('Z')\n",
    "\n",
    "        gates = [qiskit.circuit.library.PauliGate(i) for i in tomopaulis]\n",
    "        subexps = [StateTomography(gate, qubits=[i]) for i, gate in enumerate(gates)]\n",
    "        tomoexp = ParallelExperiment(subexps)\n",
    "        tomodata = tomoexp.run(backend, seed_simulation=100).block_for_results()\n",
    "\n",
    "        fidel_actual = []\n",
    "        for i, expdata in enumerate(tomodata.child_data()):\n",
    "            state_result_i = expdata.analysis_results(\"state\")\n",
    "            fidelity_result_i = expdata.analysis_results(\"state_fidelity\")\n",
    "            fidel_actual.append(fidelity_result_i.value)\n",
    "            \n",
    "        #datum=[wj, , , fidel_actual]\n",
    "        #data.append(datum)\n",
    "        fidelity_actual.append(fidel_actual)\n",
    "        operator_list.append(wj)\n",
    "        \n",
    "        \n",
    "    return expvals_theo, expvals_exp, fidelity_actual, operator_list, diagnosis\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6084cfc4",
   "metadata": {},
   "source": [
    "fidelities = []\n",
    "fidelity = 0.0\n",
    "pj = []\n",
    "P_j = 0.0\n",
    "fidel_normal = []\n",
    "data, fidel_actual = data_generator(5, 2**10)\n",
    "print(len(data[0]))\n",
    "for j in range(5-1): #loop over batches\n",
    "    for i in range(2**(2*5)-1):\n",
    "        fidelity += np.sqrt(data[0][1][j]*data[0][2][j]) / np.sqrt(2**(2*5))\n",
    "    fidelities.append(fidelity)\n",
    "for j in range(5-1):\n",
    "    for i in range(2**(2*5)-1):\n",
    "        P_j += data[i][1][j] **2 / 2**5\n",
    "    pj.append(P_j)\n",
    "for j in range(5-1):\n",
    "    a = fidelities[j] / pj[j] #since P_j = sum(a_j **2 / 2**n) = 1, we normalize fidelity using it\n",
    "    fidel_normal.append(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2324bbb3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diag\n",
      "['XY', 'XY', 'XI', 'XI', 'XY', 'XY', 'XI', 'XI', 'IX', 'IX', 'YY', 'YY', 'IY', 'IY', 'YY', 'YY', 'XZ', 'XZ', 'ZZ', 'ZZ', 'XY', 'XY', 'YI', 'YI', 'YI', 'YI', 'IY', 'IY', 'ZX', 'ZX', 'ZZ', 'ZZ']\n",
      "oplist\n",
      "[[0.9980243147217881, 0.9998693978072786], [0.9996303846161662, 0.999596131945591], [0.9999923707800885, 0.9991429481018974], [0.9994050172531763, 0.9997179512364855], [0.9997769894997898, 0.9996551270379711], [0.9991960881899813, 0.9996322877488868], [0.9998379541768132, 0.9998703507372033], [0.9986540974250391, 0.9999570901801528], [0.9975387401937004, 0.9990708565475692], [0.9998236635789504, 0.9998122319831393], [0.9992198169239579, 0.9999847419093948], [0.9992720320517969, 0.9997693704835461], [0.9997779419013219, 0.9997617518157436], [0.9999075192557039, 0.9985822174479492], [0.9999446960665778, 0.9989182394004351], [0.9990073280513444, 0.9998093742067408]]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (122,) (2,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (122,) (2,) "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "n_qubits = 2\n",
    "expval_th, expval_exp, fidel_actual, op_list, diagnosis = data_generator(n_qubits)\n",
    "print('diag')\n",
    "print(diagnosis)\n",
    "print('oplist')\n",
    "print(fidel_actual)\n",
    "xdata = np.concatenate([np.array([op_list], dtype=object), np.array([expval_exp], dtype=object)])\n",
    "domain = np.linspace(0.9,1.0,122)\n",
    "intervals = []\n",
    "Ydata = np.array([fidel_actual], dtype=object)\n",
    "\n",
    "def classifier():\n",
    "    lst = []\n",
    "    for j in range(n_qubits):\n",
    "        for k in range(2**(2*n_qubits)):\n",
    "            for i in range(len(domain)):\n",
    "                if fidel_actual[k][j] < domain[i]:\n",
    "                    lst.append(str(domain[i]))\n",
    "    return lst\n",
    "results = []\n",
    "for f in fidel_actual:\n",
    "    index = np.argmin(np.abs(domain - f))\n",
    "    d = domain[index]\n",
    "    result = fidel_actual_reshaped[index]\n",
    "    results.append(result)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "ydata = results\n",
    "print(ydata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b99298e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "2\n",
      "37\n",
      "0\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found array with dim 3. Estimator expected <= 2.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_9804\\2073675750.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mOutputCodeClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mLinearSVC\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcode_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mydata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m '''xtrain, xtest, ytrain, ytest = train_test_split(xdata, ydata, test_size=0.2, random_state=31)\n",
      "\u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\multiclass.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m   1071\u001b[0m         )\n\u001b[0;32m   1072\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1073\u001b[1;33m         self.estimators_ = Parallel(n_jobs=self.n_jobs)(\n\u001b[0m\u001b[0;32m   1074\u001b[0m             \u001b[0mdelayed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_fit_binary\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1075\u001b[0m         )\n",
      "\u001b[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1041\u001b[0m             \u001b[1;31m# remaining jobs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1042\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1043\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1044\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1045\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    859\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    860\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 861\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    862\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    863\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    777\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    778\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 779\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    780\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    781\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    570\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 572\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    214\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    215\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 216\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    217\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    218\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\multiclass.py\u001b[0m in \u001b[0;36m_fit_binary\u001b[1;34m(estimator, X, y, classes)\u001b[0m\n\u001b[0;32m     80\u001b[0m                 \u001b[1;34m\"Label %s is present in all training examples.\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclasses\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m             )\n\u001b[1;32m---> 82\u001b[1;33m         \u001b[0mestimator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_ConstantPredictor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0munique_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     83\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m         \u001b[0mestimator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\multiclass.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    120\u001b[0m             \u001b[0mforce_all_finite\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    121\u001b[0m         )\n\u001b[1;32m--> 122\u001b[1;33m         self._validate_data(\n\u001b[0m\u001b[0;32m    123\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidate_separately\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    124\u001b[0m         )\n",
      "\u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    576\u001b[0m                 \u001b[1;31m# :(\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    577\u001b[0m                 \u001b[0mcheck_X_params\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_y_params\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalidate_separately\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 578\u001b[1;33m                 \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_X_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    579\u001b[0m                 \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    580\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    792\u001b[0m                 ) from e\n\u001b[0;32m    793\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mallow_nd\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 794\u001b[1;33m             raise ValueError(\n\u001b[0m\u001b[0;32m    795\u001b[0m                 \u001b[1;34m\"Found array with dim %d. %s expected <= 2.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    796\u001b[0m                 \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mestimator_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Found array with dim 3. Estimator expected <= 2."
     ]
    }
   ],
   "source": [
    "print(len(fidel_actual))\n",
    "print(len(xdata))\n",
    "\n",
    "print(len(ydata))\n",
    "\n",
    "#y_data = np.concatenate(np.array([ydata]), np.zeros([2]))\n",
    "#y_data = np.vstack((ydata, np.zeros([3])))\n",
    "batch_size = 2**(2*n_qubits)\n",
    "print(len(intervals))\n",
    "xtrain, ytrain = [], []\n",
    "for i in range(int(batch_size*0.8)):\n",
    "    [xtrain.append(xdata[j][i]) for j in range(n_qubits)]\n",
    "    ytrain.append(ydata[i])\n",
    "    \n",
    "from sklearn.multiclass import OutputCodeClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "clf = OutputCodeClassifier(LinearSVC(random_state=0),code_size=4, random_state=0, n_jobs=1)\n",
    "clf.fit(xdata, ydata).predict(xdata)\n",
    "\n",
    "'''xtrain, xtest, ytrain, ytest = train_test_split(xdata, ydata, test_size=0.2, random_state=31)\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dtree_model = DecisionTreeClassifier(max_depth=3).fit(xtrain, ytrain)\n",
    "dtree_predictions = dtree_model.predict(xtest)\n",
    "\n",
    "cm = confusion_matrix(ytest, dtree_predictions)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2626d839",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "domain = np.linspace(0.8,1.0,122)\n",
    "labels = []\n",
    "intervals = []\n",
    "for i in range(len(domain)):\n",
    "    labels.append(str(domain[i]))\n",
    "    intervals.append(domain[i])\n",
    "\n",
    "print(a[0][1][1])\n",
    "#print(a[0][1]) # 0th sample, 1st column, 4th element\n",
    "def labeler(data, n_qubits, qubit_location):\n",
    "    _fidelity = 0.0\n",
    "    P_j = 0.0\n",
    "    for i in range(2**10-1):\n",
    "        _fidelity += np.sqrt(a[i][1][qubit_location]*a[i][2][qubit_location]) / np.sqrt(2**10)\n",
    "    \n",
    "    for i in range(2**10-1):\n",
    "        P_j += a[i][1][2] **2 / 2**5\n",
    "    fidel_normalized = _fidelity / P_j\n",
    "    for i in range(len(domain)-1):\n",
    "        if domain[i] < fidel_normalized < domain[i+1]:\n",
    "            return intervals[i]\n",
    "\n",
    "\n",
    "print(labeler(a, 5, 0), f'+- {0.2/122}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc563372",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing necessary libraries\n",
    "from sklearn import datasets\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split\n",
    "\n",
    "#print(X)\n",
    "#print(type(a))\n",
    "#b = np.asarray(a[1], dtype=object)\n",
    "#print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c230dee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5cfa57f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8255ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac6d64e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## quantum neural network\n",
    "\n",
    "\n",
    "n_qubits = 5\n",
    "q_depth = 6\n",
    "dev = qml.device('default.qubit', wires=n_qubits)\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "q_delta = 0.01\n",
    "print('is cuda available? ',torch.cuda.is_available())\n",
    "\n",
    "# quantum layers\n",
    "def H_layer(nqubits):\n",
    "    for i in range(nqubits):\n",
    "        qml.Hadamard(wires=i) #superposing states\n",
    "def RY_layer(theta_):\n",
    "    for i, th in enumerate(theta_):\n",
    "        qml.RY(th, wires=i) #rotating states\n",
    "def entangler_layer(nqubits): # layer of cnots cross-firing. cnot[0,1]-cnot[1,2]-cnot[2,3]-...\n",
    "    for i in range(0,nqubits-1, 2):  # evens\n",
    "        qml.CNOT(wires=[i, i+1])\n",
    "    for i in range(1,nqubits-1, 2): # odds\n",
    "        qml.CNOT(wires=[i, i+1])   #entangling states\n",
    "    \n",
    "# variational circuit\n",
    "dev = qml.device('default.qubit', wires=n_qubits)\n",
    "@qml.qnode(dev, interface='torch')\n",
    "\n",
    "def q_net(theta, q_weights_flat):\n",
    "    q_weights = q_weights_flat.reshape(q_depth,n_qubits)\n",
    "    H_layer(n_qubits) #superpose\n",
    "    RY_layer(theta)   #embed features in qnode\n",
    "    for i in range(q_depth):  #sequence of trainable variatinal layers\n",
    "        entangler_layer(n_qubits)\n",
    "        RY_layer(q_weights[i])\n",
    "    exp_vals = [qml.expval(qml.PauliZ(i)) for i in range(n_qubits)] \n",
    "    print('exp.vals = ', tuple(exp_vals))\n",
    "    \n",
    "    return tuple(exp_vals)\n",
    "\n",
    "class dressedQnetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.preprocess = nn.Linear(512, n_qubits)\n",
    "        self.preprocess = nn.Dropout(p=0.5)\n",
    "        self.thetas = nn.Parameter(q_delta * torch.randn(q_depth * n_qubits))\n",
    "        self.postprocess = nn.Linear(n_qubits, 2)\n",
    "\n",
    "    def forward(self, input_features):\n",
    "        print('features: ', input_features)\n",
    "        print(len(input_features[0]))\n",
    "        output_pre = self.pre_net(input_features)\n",
    "        theta = torch.tanh(output_pre) * np.pi / 2.0  #nonlinear activation on q.layer\n",
    "\n",
    "        output_q = torch.Tensor(0, n_qubits)\n",
    "        output_q = output_q.to(device)\n",
    "        for th in theta:\n",
    "            q_out = q_net(th, self.thetas).float().unsqueeze(0)\n",
    "            output_q = torch.cat((output_q, q_out))\n",
    "\n",
    "        return self.postprocess(output_q)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
